{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3b13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "\n",
    "fake = Faker()\n",
    "num_records = 10000\n",
    "\n",
    "data = {\n",
    "    'SUBJECT_ID': [fake.unique.random_number(digits=7) for _ in range(num_records)],\n",
    "    'HADM_ID': [fake.unique.random_number(digits=7) for _ in range(num_records)],\n",
    "    'ICUSTAY_ID': [fake.unique.random_number(digits=7) for _ in range(num_records)],\n",
    "    'ADMITTIME': [fake.date_time_between(start_date='-10y', end_date='now') for _ in range(num_records)],\n",
    "    'AGE': np.random.randint(18, 90, num_records),\n",
    "    'heart_rate': np.round(np.random.normal(80, 15, num_records), 2),\n",
    "    'blood_pressure': np.round(np.random.normal(120, 20, num_records), 2),\n",
    "    'respiratory_rate': np.round(np.random.normal(18, 5, num_records), 2),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['ADMITTIME'] = pd.to_datetime(df['ADMITTIME'])\n",
    "df.sort_values(by=['SUBJECT_ID', 'ADMITTIME'], inplace=True)\n",
    "df.to_csv('synthetic_mimic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac6ca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.singlecomplex` was removed in the NumPy 2.0 release. Use `np.complex64` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timeseries\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numerical\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\__init__.py:54\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPython >= 3.10 required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# config,; logutils,; viz,\u001b[39;00m\n\u001b[32m     55\u001b[39m     datasets,\n\u001b[32m     56\u001b[39m     encoders,\n\u001b[32m     57\u001b[39m     metrics,\n\u001b[32m     58\u001b[39m     models,\n\u001b[32m     59\u001b[39m     optimizers,\n\u001b[32m     60\u001b[39m     random,\n\u001b[32m     61\u001b[39m     tasks,\n\u001b[32m     62\u001b[39m     utils,\n\u001b[32m     63\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# pylint: enable=wrong-import-position\u001b[39;00m\n\u001b[32m     67\u001b[39m __version__ = metadata.version(__package__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\datasets\\__init__.py:53\u001b[39m\n\u001b[32m     20\u001b[39m __all__ = [\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Sub-Modules\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbase\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUSHCN_DeBrouwer2019\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     49\u001b[39m ]\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Final, TypeAlias\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     55\u001b[39m     DATASET_OBJECT,\n\u001b[32m     56\u001b[39m     BaseDataset,\n\u001b[32m     57\u001b[39m     MultiFrameDataset,\n\u001b[32m     58\u001b[39m     SingleFrameDataset,\n\u001b[32m     59\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeijing_air_quality\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeijingAirQuality\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\datasets\\base.py:32\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame, Series\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DATASETDIR, RAWDATADIR\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flatten_nested, paths_exists, prepend_path\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mremote\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeyVar, Nested, PathType\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\utils\\__init__.py:34\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Provides utility functions.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m __all__ = [\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Sub-Packages\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpairwise_disjoint\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data, decorators, remote, system, types\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclassing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PatchedABCMeta, abstractattribute\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     Split,\n\u001b[32m     38\u001b[39m     deep_dict_update,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     round_relative,\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\utils\\data\\__init__.py:33\u001b[39m\n\u001b[32m      3\u001b[39m __all__ = [\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Types\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIndexedArray\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munpack_sequence\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     collate_list,\n\u001b[32m     28\u001b[39m     collate_packed,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     unpad_sequence,\n\u001b[32m     32\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetCollection, MappingDataset\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfolds\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     folds_as_frame,\n\u001b[32m     36\u001b[39m     folds_as_sparse_frame,\n\u001b[32m     37\u001b[39m     folds_from_groups,\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     IndexedArray,\n\u001b[32m     41\u001b[39m     TimeSeriesBatch,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     TimeTensor,\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\utils\\data\\datasets.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame, MultiIndex\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m repr_mapping\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMappingDataset\u001b[39;00m(Dataset, Mapping):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Represents a Mapping[Key, Dataset].\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33;03m    ``ds[key]`` returns the dataset for the given key.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33;03m    ``ds[(key, subkey)]=ds[key][subkey]``\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\utils\\strings.py:28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPESTRINGS, ScalarDType\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtsdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocols\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Array, NTuple\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__dir__\u001b[39m() -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Desktop\\itsf-code\\tsdm\\utils\\types\\dtypes.py:108\u001b[39m\n\u001b[32m     89\u001b[39m NUMPY_FLOAT_TYPECODES: Final[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m[np.floating], \u001b[38;5;28mstr\u001b[39m]] = {\n\u001b[32m     90\u001b[39m     np.float64: \u001b[33m\"\u001b[39m\u001b[33md\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m     np.float16: \u001b[33m\"\u001b[39m\u001b[33me\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[38;5;66;03m# np.longfloat: \"g\",\u001b[39;00m\n\u001b[32m    100\u001b[39m }\n\u001b[32m    101\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Dictionary of all `numpy` float data type typecodes.\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m NUMPY_COMPLEX_TYPECODES: Final[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m[np.complexfloating], \u001b[38;5;28mstr\u001b[39m]] = {\n\u001b[32m    104\u001b[39m     np.complex64: \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m     np.complex128: \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# np.complex256: \"G\",\u001b[39;00m\n\u001b[32m    107\u001b[39m     np.csingle: \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msinglecomplex\u001b[49m: \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m     np.cdouble: \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m     np.cfloat: \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    111\u001b[39m     np.complex_: \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m     np.clongdouble: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m     np.clongfloat: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m     np.longcomplex: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m }\n\u001b[32m    116\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Dictionary of all `numpy` complex data types.\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m NUMPY_TIME_TYPECODES: Final[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m[np.generic], \u001b[38;5;28mstr\u001b[39m]] = {\n\u001b[32m    120\u001b[39m     np.timedelta64: \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# timedelta64\u001b[39;00m\n\u001b[32m    121\u001b[39m     np.datetime64: \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# datetime64\u001b[39;00m\n\u001b[32m    122\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yazda\\Miniconda3\\envs\\thesis_py311\\Lib\\site-packages\\numpy\\__init__.py:414\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    415\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    416\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    417\u001b[39m         name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    418\u001b[39m     )\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33mchararray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    421\u001b[39m     warnings.warn(\n\u001b[32m    422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor bytes dtype instead.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: `np.singlecomplex` was removed in the NumPy 2.0 release. Use `np.complex64` instead."
     ]
    }
   ],
   "source": [
    "from tsdm.utils.data import timeseries\n",
    "from tsdm.encoders import numerical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('synthetic_mimic.csv')\n",
    "\n",
    "# Ensure datetime format\n",
    "df['ADMITTIME'] = pd.to_datetime(df['ADMITTIME'])\n",
    "df['timestamp'] = df.groupby('SUBJECT_ID').cumcount()\n",
    "\n",
    "# Handle missing values by introducing NaNs randomly (simulate irregularity)\n",
    "for col in ['heart_rate', 'blood_pressure', 'respiratory_rate']:\n",
    "    df.loc[df.sample(frac=0.1).index, col] = np.nan\n",
    "\n",
    "# Encode and normalize numerical features\n",
    "encoder = numerical.Standardizer()\n",
    "df[['heart_rate', 'blood_pressure', 'respiratory_rate']] = encoder.fit_transform(\n",
    "    df[['heart_rate', 'blood_pressure', 'respiratory_rate']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ce3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticIrregularDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, subject_col='SUBJECT_ID', time_col='timestamp', features=['heart_rate', 'blood_pressure', 'respiratory_rate']):\n",
    "        self.subject_ids = df[subject_col].unique()\n",
    "        self.data = df\n",
    "        self.time_col = time_col\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subject_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.subject_ids[idx]\n",
    "        subject_data = self.data[self.data['SUBJECT_ID'] == subject_id]\n",
    "\n",
    "        times = torch.tensor(subject_data[self.time_col].values, dtype=torch.float32)\n",
    "        features = torch.tensor(subject_data[self.features].values, dtype=torch.float32)\n",
    "\n",
    "        mask = ~torch.isnan(features)\n",
    "        features = torch.nan_to_num(features)\n",
    "\n",
    "        return times, features, mask\n",
    "\n",
    "dataset = SyntheticIrregularDataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    times, features, masks = zip(*batch)\n",
    "    pad = torch.nn.utils.rnn.pad_sequence\n",
    "\n",
    "    times_padded = pad(times, batch_first=True, padding_value=0)\n",
    "    features_padded = pad(features, batch_first=True, padding_value=0)\n",
    "    masks_padded = pad(masks, batch_first=True, padding_value=False)\n",
    "\n",
    "    return times_padded, features_padded, masks_padded\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.fld_icc import FLD\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = FLD(\n",
    "    input_dim=3,\n",
    "    latent_dim=20,\n",
    "    num_heads=4,\n",
    "    embed_dim=64,\n",
    "    function='L'\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for times, features, masks in loader:\n",
    "        times, features, masks = times.to(device), features.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(times, features, masks, times)  # Using same times for simplicity\n",
    "\n",
    "        loss = criterion(outputs[masks], features[masks])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
